{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b5883091",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), \"../../\"))\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)\n",
    "from dataspaces_utils.common import get_s3_client, bucket, pd\n",
    "import xml.etree.ElementTree as ET\n",
    "import pandas as pd\n",
    "from fitparse import FitFile\n",
    "import os\n",
    "from io import BytesIO  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "55f6f218",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = get_s3_client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c78c9f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_fit_to_df(file_bytes):\n",
    "    fitfile = FitFile(BytesIO(file_bytes))\n",
    "    records = []\n",
    "    for record in fitfile.get_messages(\"record\"):\n",
    "        row = {}\n",
    "        for field in record:\n",
    "            row[field.name] = field.value\n",
    "        records.append(row)\n",
    "    return pd.DataFrame(records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0ba13d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_tcx_to_df(file_bytes):\n",
    "    tree = ET.ElementTree(ET.fromstring(file_bytes.decode(\"utf-8\")))\n",
    "    ns = {'tcx': 'http://www.garmin.com/xmlschemas/TrainingCenterDatabase/v2'}\n",
    "    records = []\n",
    "    for tp in tree.findall('.//tcx:Trackpoint', ns):\n",
    "        record = {}\n",
    "        # 1. Timestamp\n",
    "        time_elem = tp.find('tcx:Time', ns)\n",
    "        if time_elem is not None:\n",
    "            record['timestamp'] = pd.to_datetime(time_elem.text)\n",
    "        # 2. Speed (basic)\n",
    "        speed_elem = tp.find('tcx:Speed', ns)\n",
    "        if speed_elem is not None:\n",
    "            record['speed'] = float(speed_elem.text)\n",
    "        # 3. Cadence\n",
    "        cadence_elem = tp.find('tcx:Cadence', ns)\n",
    "        if cadence_elem is not None:\n",
    "            record['cadence'] = float(cadence_elem.text)\n",
    "        # 4. Heart rate\n",
    "        hr_elem = tp.find('.//tcx:HeartRateBpm/tcx:Value', ns)\n",
    "        if hr_elem is not None:\n",
    "            record['heart_rate'] = int(hr_elem.text)\n",
    "        # 5. Power (and speed) inside Extensions > TPX\n",
    "        extensions_elem = tp.find('tcx:Extensions', ns)\n",
    "        if extensions_elem is not None:\n",
    "            tpx_elem = extensions_elem.find('.//', ns)\n",
    "            if tpx_elem is not None:\n",
    "                for elem in tpx_elem:\n",
    "                    tag = elem.tag.split('}')[-1].lower()\n",
    "                    if tag == 'watts':\n",
    "                        record['power'] = float(elem.text)\n",
    "                    elif tag == 'speed':\n",
    "                        record['speed'] = float(elem.text)  # Override if found here\n",
    "        # Append record if it has a timestamp (required)\n",
    "        if 'timestamp' in record:\n",
    "            records.append(record)\n",
    "    return pd.DataFrame(records)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "00db6976",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available files:\n",
      "üîπ bronze/original/bronze_activity_2025-04-14_bf81db1b.fit\n",
      "üîπ bronze/original/bronze_activity_2025-04-14_f5a06ce9.tcx\n",
      "üîπ bronze/original/bronze_activity_2025-04-26_2ff07ffe.fit\n",
      "\n",
      "‚úÖ Testing file: bronze/original/bronze_activity_2025-04-14_bf81db1b.fit\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>altitude</th>\n",
       "      <th>distance</th>\n",
       "      <th>enhanced_altitude</th>\n",
       "      <th>heart_rate</th>\n",
       "      <th>temperature</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>enhanced_speed</th>\n",
       "      <th>speed</th>\n",
       "      <th>cadence</th>\n",
       "      <th>fractional_cadence</th>\n",
       "      <th>unknown_87</th>\n",
       "      <th>accumulated_power</th>\n",
       "      <th>power</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>74.2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>74.2</td>\n",
       "      <td>95</td>\n",
       "      <td>21</td>\n",
       "      <td>2025-04-14 17:52:23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>74.2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>74.2</td>\n",
       "      <td>95</td>\n",
       "      <td>21</td>\n",
       "      <td>2025-04-14 17:52:24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>74.2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>74.2</td>\n",
       "      <td>96</td>\n",
       "      <td>21</td>\n",
       "      <td>2025-04-14 17:52:25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>74.2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>74.2</td>\n",
       "      <td>98</td>\n",
       "      <td>21</td>\n",
       "      <td>2025-04-14 17:52:26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>74.2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>74.2</td>\n",
       "      <td>99</td>\n",
       "      <td>21</td>\n",
       "      <td>2025-04-14 17:52:27</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4120</th>\n",
       "      <td>74.2</td>\n",
       "      <td>5990.58</td>\n",
       "      <td>74.2</td>\n",
       "      <td>99</td>\n",
       "      <td>21</td>\n",
       "      <td>2025-04-14 19:01:03</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10041.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4121</th>\n",
       "      <td>74.2</td>\n",
       "      <td>5990.58</td>\n",
       "      <td>74.2</td>\n",
       "      <td>99</td>\n",
       "      <td>21</td>\n",
       "      <td>2025-04-14 19:01:04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10041.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4122</th>\n",
       "      <td>74.2</td>\n",
       "      <td>5990.58</td>\n",
       "      <td>74.2</td>\n",
       "      <td>98</td>\n",
       "      <td>21</td>\n",
       "      <td>2025-04-14 19:01:05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10041.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4123</th>\n",
       "      <td>74.2</td>\n",
       "      <td>5990.58</td>\n",
       "      <td>74.2</td>\n",
       "      <td>97</td>\n",
       "      <td>21</td>\n",
       "      <td>2025-04-14 19:01:06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10041.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4124</th>\n",
       "      <td>74.2</td>\n",
       "      <td>5990.58</td>\n",
       "      <td>74.2</td>\n",
       "      <td>97</td>\n",
       "      <td>21</td>\n",
       "      <td>2025-04-14 19:01:07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10041.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4125 rows √ó 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      altitude  distance  enhanced_altitude  heart_rate  temperature  \\\n",
       "0         74.2      0.00               74.2          95           21   \n",
       "1         74.2      0.00               74.2          95           21   \n",
       "2         74.2      0.00               74.2          96           21   \n",
       "3         74.2      0.00               74.2          98           21   \n",
       "4         74.2      0.00               74.2          99           21   \n",
       "...        ...       ...                ...         ...          ...   \n",
       "4120      74.2   5990.58               74.2          99           21   \n",
       "4121      74.2   5990.58               74.2          99           21   \n",
       "4122      74.2   5990.58               74.2          98           21   \n",
       "4123      74.2   5990.58               74.2          97           21   \n",
       "4124      74.2   5990.58               74.2          97           21   \n",
       "\n",
       "               timestamp  enhanced_speed  speed  cadence  fractional_cadence  \\\n",
       "0    2025-04-14 17:52:23             NaN    NaN      NaN                 NaN   \n",
       "1    2025-04-14 17:52:24             NaN    NaN      NaN                 NaN   \n",
       "2    2025-04-14 17:52:25             NaN    NaN      NaN                 NaN   \n",
       "3    2025-04-14 17:52:26             NaN    NaN      NaN                 NaN   \n",
       "4    2025-04-14 17:52:27             NaN    NaN      NaN                 NaN   \n",
       "...                  ...             ...    ...      ...                 ...   \n",
       "4120 2025-04-14 19:01:03             0.0    0.0      0.0                 0.0   \n",
       "4121 2025-04-14 19:01:04             0.0    0.0      0.0                 0.0   \n",
       "4122 2025-04-14 19:01:05             0.0    0.0      0.0                 0.0   \n",
       "4123 2025-04-14 19:01:06             0.0    0.0      0.0                 0.0   \n",
       "4124 2025-04-14 19:01:07             0.0    0.0      0.0                 0.0   \n",
       "\n",
       "      unknown_87  accumulated_power  power  \n",
       "0            NaN                NaN    NaN  \n",
       "1            NaN                NaN    NaN  \n",
       "2            NaN                NaN    NaN  \n",
       "3            NaN                NaN    NaN  \n",
       "4            NaN                NaN    NaN  \n",
       "...          ...                ...    ...  \n",
       "4120         0.0            10041.0    0.0  \n",
       "4121         0.0            10041.0    0.0  \n",
       "4122         0.0            10041.0    0.0  \n",
       "4123         0.0            10041.0    0.0  \n",
       "4124         0.0            10041.0    0.0  \n",
       "\n",
       "[4125 rows x 13 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# üì• Select one .fit or .tcx file from bronze/original\n",
    "response = s3.list_objects_v2(Bucket=bucket, Prefix=\"bronze/original/\")\n",
    "keys = [obj[\"Key\"] for obj in response.get(\"Contents\", []) if obj[\"Key\"].endswith((\".fit\", \".tcx\"))]\n",
    "\n",
    "# Show available files\n",
    "print(\"Available files:\")\n",
    "for key in keys:\n",
    "    print(\"üîπ\", key)\n",
    "\n",
    "# üîß Choose a file to test\n",
    "test_key = keys[0]  # Change index if you want another one\n",
    "print(f\"\\n‚úÖ Testing file: {test_key}\")\n",
    "\n",
    "# Download file from S3\n",
    "obj = s3.get_object(Bucket=bucket, Key=test_key)\n",
    "file_bytes = obj[\"Body\"].read()\n",
    "extension = os.path.splitext(test_key)[-1]\n",
    "\n",
    "# Run the parser\n",
    "try:\n",
    "    if extension == \".fit\":\n",
    "        df = parse_fit_to_df(file_bytes)\n",
    "        display(df)\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error during parsing: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "62ecd96e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available files:\n",
      "üîπ bronze/original/bronze_activity_2025-04-14_bf81db1b.fit\n",
      "üîπ bronze/original/bronze_activity_2025-04-14_f5a06ce9.tcx\n",
      "üîπ bronze/original/bronze_activity_2025-04-26_2ff07ffe.fit\n",
      "\n",
      "‚úÖ Testing file: bronze/original/bronze_activity_2025-04-14_f5a06ce9.tcx\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>cadence</th>\n",
       "      <th>heart_rate</th>\n",
       "      <th>speed</th>\n",
       "      <th>power</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-04-14 17:52:02.618000+00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-04-14 17:52:03.618000+00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.886672</td>\n",
       "      <td>106.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-04-14 17:52:04.618000+00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.859050</td>\n",
       "      <td>106.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025-04-14 17:52:05.618000+00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.893552</td>\n",
       "      <td>106.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025-04-14 17:52:06.618000+00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.893552</td>\n",
       "      <td>107.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3837</th>\n",
       "      <td>2025-04-14 18:55:59.618000+00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.549858</td>\n",
       "      <td>49.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3838</th>\n",
       "      <td>2025-04-14 18:56:00.618000+00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.953638</td>\n",
       "      <td>36.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3839</th>\n",
       "      <td>2025-04-14 18:56:01.618000+00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.420653</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3840</th>\n",
       "      <td>2025-04-14 18:56:02.618000+00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.966114</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3841</th>\n",
       "      <td>2025-04-14 18:56:03.618000+00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.561103</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3842 rows √ó 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            timestamp  cadence  heart_rate     speed  power\n",
       "0    2025-04-14 17:52:02.618000+00:00      0.0           0  0.000000    0.0\n",
       "1    2025-04-14 17:52:03.618000+00:00      0.0           0  6.886672  106.0\n",
       "2    2025-04-14 17:52:04.618000+00:00      0.0           0  6.859050  106.0\n",
       "3    2025-04-14 17:52:05.618000+00:00      0.0           0  6.893552  106.0\n",
       "4    2025-04-14 17:52:06.618000+00:00      0.0           0  6.893552  107.0\n",
       "...                               ...      ...         ...       ...    ...\n",
       "3837 2025-04-14 18:55:59.618000+00:00      0.0           0  2.549858   49.0\n",
       "3838 2025-04-14 18:56:00.618000+00:00      0.0           0  1.953638   36.0\n",
       "3839 2025-04-14 18:56:01.618000+00:00      0.0           0  1.420653   24.0\n",
       "3840 2025-04-14 18:56:02.618000+00:00      0.0           0  0.966114   16.0\n",
       "3841 2025-04-14 18:56:03.618000+00:00      0.0           0  0.561103    8.0\n",
       "\n",
       "[3842 rows x 5 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# üì• Select one .fit or .tcx file from bronze/original\n",
    "response = s3.list_objects_v2(Bucket=bucket, Prefix=\"bronze/original/\")\n",
    "keys = [obj[\"Key\"] for obj in response.get(\"Contents\", []) if obj[\"Key\"].endswith((\".fit\", \".tcx\"))]\n",
    "\n",
    "# Show available files\n",
    "print(\"Available files:\")\n",
    "for key in keys:\n",
    "    print(\"üîπ\", key)\n",
    "\n",
    "# üîß Choose a file to test\n",
    "test_key = keys[1]  # Change index if you want another one\n",
    "print(f\"\\n‚úÖ Testing file: {test_key}\")\n",
    "\n",
    "# Download file from S3\n",
    "obj = s3.get_object(Bucket=bucket, Key=test_key)\n",
    "file_bytes = obj[\"Body\"].read()\n",
    "extension = os.path.splitext(test_key)[-1]\n",
    "\n",
    "# Run the parser\n",
    "try:\n",
    "    if extension == \".tcx\":\n",
    "        df = parse_tcx_to_df(file_bytes)\n",
    "        display(df)\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error during parsing: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b8b67b16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: bronze/original/bronze_activity_2025-04-14_bf81db1b.fit\n",
      "Saved directly to Supabase: bronze/parquet/bronze_activity_2025-04-14_bf81db1b.parquet\n",
      "Processing: bronze/original/bronze_activity_2025-04-14_f5a06ce9.tcx\n",
      "Saved directly to Supabase: bronze/parquet/bronze_activity_2025-04-14_f5a06ce9.parquet\n",
      "Processing: bronze/original/bronze_activity_2025-04-26_2ff07ffe.fit\n",
      "Saved directly to Supabase: bronze/parquet/bronze_activity_2025-04-26_2ff07ffe.parquet\n"
     ]
    }
   ],
   "source": [
    "# List .fit and .tcx files in bronze/original/\n",
    "response = s3.list_objects_v2(Bucket=bucket, Prefix=\"bronze/original/\")\n",
    "keys = [obj[\"Key\"] for obj in response.get(\"Contents\", []) if obj[\"Key\"].endswith((\".fit\", \".tcx\"))]\n",
    "\n",
    "for key in keys:\n",
    "    print(f\"Processing: {key}\")\n",
    "    extension = os.path.splitext(key)[-1]\n",
    "\n",
    "    obj = s3.get_object(Bucket=bucket, Key=key)\n",
    "    file_bytes = obj[\"Body\"].read()\n",
    "\n",
    "    # Parse\n",
    "    try:\n",
    "        if extension == \".fit\":\n",
    "            df = parse_fit_to_df(file_bytes)\n",
    "        elif extension == \".tcx\":\n",
    "            df = parse_tcx_to_df(file_bytes)\n",
    "        else:\n",
    "            print(f\"Unknown extension: {extension}\")\n",
    "            continue\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to parse {key}: {e}\")\n",
    "        continue\n",
    "\n",
    "    if df.empty:\n",
    "        print(f\"Empty DataFrame for {key}, skipping.\")\n",
    "        continue\n",
    "\n",
    "    # Sanitize unsupported types (e.g., objects, time) before saving\n",
    "    for col in df.columns:\n",
    "        if df[col].dtype == \"object\":\n",
    "            df[col] = df[col].astype(str)\n",
    "\n",
    "    # Define S3 key\n",
    "    bronze_name = os.path.basename(key).replace(extension, \".parquet\")\n",
    "    s3_key = f\"bronze/parquet/{bronze_name}\"\n",
    "\n",
    "    # Convert DataFrame to Parquet in memory\n",
    "    try:\n",
    "        # Create Parquet in memory\n",
    "        buffer = BytesIO()\n",
    "        df.to_parquet(buffer, index=False, engine=\"pyarrow\")\n",
    "        buffer.seek(0)  \n",
    "\n",
    "        # # Upload safely\n",
    "        # s3.put_object(\n",
    "        #     Bucket=bucket,\n",
    "        #     Key=s3_key,\n",
    "        #     Body=buffer.read(),  \n",
    "        #     ContentType=\"application/octet-stream\"\n",
    "        # )\n",
    "        # Upload using upload_fileobj ‚Äî safest for binary streams\n",
    "        s3.upload_fileobj(\n",
    "            Fileobj=buffer,\n",
    "            Bucket=bucket,\n",
    "            Key=s3_key\n",
    "        )\n",
    "        print(f\"Saved directly to Supabase: {s3_key}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to save/upload parquet for {key}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d82a13b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ùå Error reading Parquet file from bronze/parquet/bronze_activity_2025-04-26_2ff07ffe.parquet: Could not open Parquet input source '<Buffer>': Parquet magic bytes not found in footer. Either the file is corrupted or this is not a parquet file.\n"
     ]
    }
   ],
   "source": [
    "# Verify that the file exists and is a valid Parquet file\n",
    "try:\n",
    "\tobj = s3.get_object(Bucket=bucket, Key=s3_key)\n",
    "\tbuffer = BytesIO(obj['Body'].read())\n",
    "\t\n",
    "\t# Attempt to read the file as a Parquet file\n",
    "\tdf_check = pd.read_parquet(buffer, engine=\"pyarrow\")\n",
    "\tdisplay(df_check.head())\n",
    "except Exception as e:\n",
    "\tprint(f\"‚ùå Error reading Parquet file from {s3_key}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "13288b66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì¶ Found 3 Parquet files in bronze/parquet/\n",
      "‚¨áÔ∏è Reading: bronze/parquet/bronze_activity_2025-04-14_bf81db1b.parquet\n",
      "‚ùå Failed to read bronze/parquet/bronze_activity_2025-04-14_bf81db1b.parquet: Could not open Parquet input source '<Buffer>': Parquet magic bytes not found in footer. Either the file is corrupted or this is not a parquet file.\n",
      "‚¨áÔ∏è Reading: bronze/parquet/bronze_activity_2025-04-14_f5a06ce9.parquet\n",
      "‚ùå Failed to read bronze/parquet/bronze_activity_2025-04-14_f5a06ce9.parquet: Could not open Parquet input source '<Buffer>': Parquet magic bytes not found in footer. Either the file is corrupted or this is not a parquet file.\n",
      "‚¨áÔ∏è Reading: bronze/parquet/bronze_activity_2025-04-26_2ff07ffe.parquet\n",
      "‚ùå Failed to read bronze/parquet/bronze_activity_2025-04-26_2ff07ffe.parquet: Could not open Parquet input source '<Buffer>': Parquet magic bytes not found in footer. Either the file is corrupted or this is not a parquet file.\n",
      "‚ö†Ô∏è No valid parquet files were loaded.\n"
     ]
    }
   ],
   "source": [
    "# Setup\n",
    "s3 = get_s3_client()\n",
    "\n",
    "# List all parquet files in bronze/parquet/\n",
    "response = s3.list_objects_v2(Bucket=bucket, Prefix=\"bronze/parquet/\")\n",
    "keys = [obj[\"Key\"] for obj in response.get(\"Contents\", []) if obj[\"Key\"].endswith(\".parquet\")]\n",
    "\n",
    "print(f\"üì¶ Found {len(keys)} Parquet files in bronze/parquet/\")\n",
    "\n",
    "all_dfs = []\n",
    "\n",
    "# Loop through and read each parquet file\n",
    "for key in keys:\n",
    "    try:\n",
    "        print(f\"‚¨áÔ∏è Reading: {key}\")\n",
    "        obj = s3.get_object(Bucket=bucket, Key=key)\n",
    "        buffer = BytesIO(obj[\"Body\"].read())\n",
    "\n",
    "        df = pd.read_parquet(buffer, engine=\"pyarrow\")\n",
    "        df[\"source_file\"] = key  # Optional: track file of origin\n",
    "        all_dfs.append(df)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Failed to read {key}: {e}\")\n",
    "\n",
    "# Combine all into a single DataFrame\n",
    "if all_dfs:\n",
    "    combined_df = pd.concat(all_dfs, ignore_index=True)\n",
    "    print(f\"\\n‚úÖ Loaded {len(combined_df)} total rows from {len(all_dfs)} files\")\n",
    "    display(combined_df.head())\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No valid parquet files were loaded.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
