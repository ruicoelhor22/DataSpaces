{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b5883091",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import boto3\n",
    "import pandas as pd\n",
    "from fitparse import FitFile\n",
    "from io import BytesIO\n",
    "import xml.etree.ElementTree as ET\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Setup S3 client\n",
    "s3 = boto3.client(\n",
    "    's3',\n",
    "    endpoint_url=os.getenv(\"SUPABASE_S3_ENDPOINT\"),\n",
    "    aws_access_key_id=os.getenv(\"SUPABASE_S3_KEY_ID\"),\n",
    "    aws_secret_access_key=os.getenv(\"SUPABASE_S3_SECRET\")\n",
    ")\n",
    "\n",
    "bucket = os.getenv(\"SUPABASE_BUCKET\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0ba13d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_fit_to_df(file_bytes):\n",
    "    fitfile = FitFile(BytesIO(file_bytes))\n",
    "    records = []\n",
    "    for record in fitfile.get_messages(\"record\"):\n",
    "        row = {}\n",
    "        for field in record:\n",
    "            row[field.name] = field.value\n",
    "        records.append(row)\n",
    "    return pd.DataFrame(records)\n",
    "\n",
    "def parse_tcx_to_df(file_bytes):\n",
    "    tree = ET.ElementTree(ET.fromstring(file_bytes.decode(\"utf-8\")))\n",
    "    ns = {'tcx': 'http://www.garmin.com/xmlschemas/TrainingCenterDatabase/v2'}\n",
    "    records = []\n",
    "    for tp in tree.findall('.//tcx:Trackpoint', ns):\n",
    "        record = {}\n",
    "        # 1. Timestamp\n",
    "        time_elem = tp.find('tcx:Time', ns)\n",
    "        if time_elem is not None:\n",
    "            record['timestamp'] = pd.to_datetime(time_elem.text)\n",
    "        # 2. Speed (basic)\n",
    "        speed_elem = tp.find('tcx:Speed', ns)\n",
    "        if speed_elem is not None:\n",
    "            record['speed'] = float(speed_elem.text)\n",
    "        # 3. Cadence\n",
    "        cadence_elem = tp.find('tcx:Cadence', ns)\n",
    "        if cadence_elem is not None:\n",
    "            record['cadence'] = float(cadence_elem.text)\n",
    "        # 4. Heart rate\n",
    "        hr_elem = tp.find('.//tcx:HeartRateBpm/tcx:Value', ns)\n",
    "        if hr_elem is not None:\n",
    "            record['heart_rate'] = int(hr_elem.text)\n",
    "        # 5. Power (and speed) inside Extensions > TPX\n",
    "        extensions_elem = tp.find('tcx:Extensions', ns)\n",
    "        if extensions_elem is not None:\n",
    "            tpx_elem = extensions_elem.find('.//', ns)\n",
    "            if tpx_elem is not None:\n",
    "                for elem in tpx_elem:\n",
    "                    tag = elem.tag.split('}')[-1].lower()\n",
    "                    if tag == 'watts':\n",
    "                        record['power'] = float(elem.text)\n",
    "                    elif tag == 'speed':\n",
    "                        record['speed'] = float(elem.text)  # Override if found here\n",
    "        # Append record if it has a timestamp (required)\n",
    "        if 'timestamp' in record:\n",
    "            records.append(record)\n",
    "    return pd.DataFrame(records)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b8b67b16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: bronze/original/bronze_activity_2025-04-14_493c8809.tcx\n",
      "Saved to Supabase: bronze/parquet/bronze_activity_2025-04-14_493c8809.parquet\n",
      "Processing: bronze/original/bronze_activity_2025-04-14_6a1e0cfe.fit\n",
      "Saved to Supabase: bronze/parquet/bronze_activity_2025-04-14_6a1e0cfe.parquet\n",
      "Processing: bronze/original/bronze_activity_2025-04-26_1f6a6649.fit\n",
      "Saved to Supabase: bronze/parquet/bronze_activity_2025-04-26_1f6a6649.parquet\n"
     ]
    }
   ],
   "source": [
    "# List .fit and .tcx files in bronze/original/\n",
    "response = s3.list_objects_v2(Bucket=bucket, Prefix=\"bronze/original/\")\n",
    "keys = [obj[\"Key\"] for obj in response.get(\"Contents\", []) if obj[\"Key\"].endswith((\".fit\", \".tcx\"))]\n",
    "\n",
    "for key in keys:\n",
    "    print(f\"Processing: {key}\")\n",
    "    extension = os.path.splitext(key)[-1]\n",
    "\n",
    "    obj = s3.get_object(Bucket=bucket, Key=key)\n",
    "    file_bytes = obj[\"Body\"].read()\n",
    "\n",
    "    # Parse\n",
    "    try:\n",
    "        if extension == \".fit\":\n",
    "            df = parse_fit_to_df(file_bytes)\n",
    "        elif extension == \".tcx\":\n",
    "            df = parse_tcx_to_df(file_bytes)\n",
    "        else:\n",
    "            print(f\"Unknown extension: {extension}\")\n",
    "            continue\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to parse {key}: {e}\")\n",
    "        continue\n",
    "\n",
    "    if df.empty:\n",
    "        print(f\"Empty DataFrame for {key}, skipping.\")\n",
    "        continue\n",
    "\n",
    "    # Save to Parquet locally\n",
    "    bronze_name = os.path.basename(key).replace(extension, \".parquet\")\n",
    "    local_path = f\"bronze_local/{bronze_name}\"\n",
    "    os.makedirs(\"bronze_local/\", exist_ok=True)\n",
    "    df.to_parquet(local_path, index=False)\n",
    "\n",
    "    # Upload .parquet to bronze/parquet/ in Supabase Storage\n",
    "    s3_key = f\"bronze/parquet/{bronze_name}\"\n",
    "    with open(local_path, \"rb\") as f:\n",
    "        s3.upload_fileobj(f, bucket, s3_key)\n",
    "\n",
    "    print(f\"Saved to Supabase: {s3_key}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
